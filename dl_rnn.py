# -*- coding: utf-8 -*-
"""DL_RNN.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/10YJiFyI6G42QO6ahT6HOD2vvRfa3GOIQ
"""

import numpy as np
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Embedding, SimpleRNN, Dense
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences

text_data = ['I love this movie', 'This is terrible', 'Neutral review', 'This is the worst', 'I Like You', 'He says Bad about you']
labels = [2, 0, 1, 0, 2, 0]

tokenizer = Tokenizer()
tokenizer.fit_on_texts(text_data)
sequences = tokenizer.texts_to_sequences(text_data)

max_sequence_length = max([len(sequence) for sequence in sequences])

padded_sequences = pad_sequences(sequences, maxlen=max_sequence_length)

labels = np.array(labels)

vocab_size = len(tokenizer.word_index) + 1

model = Sequential([
    Embedding(input_dim=vocab_size, output_dim=8, input_length=max_sequence_length),
    SimpleRNN(16, return_sequences=False),
    Dense(8, activation='relu'),
    Dense(3, activation='softmax')
])

model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])

model.fit(padded_sequences, labels, epochs=10, batch_size=16rr)

test_data = ['I enjoyed the movie', 'This is the worst thing ever']
test_labels = [2, 0]
test_sequences = tokenizer.texts_to_sequences(test_data)

X_test = pad_sequences(test_sequences, maxlen=max_sequence_length)

y_test = np.array(test_labels)

loss, accuracy = model.evaluate(X_test, y_test)
print(f'Loss: {loss}, Accuracy: {accuracy}')